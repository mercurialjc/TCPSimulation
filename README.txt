1. High-level approach
(1)We used NS2 framework to create the topology, add links between nodes, and perform different simulations of 3 experiments.
(2)The trace files produced by NS2 contain the information of every single packet. We wrote 3 different perl scripts to calculate the throughput, latency and packet drop rate for each instance of simulation, and produce statisitcs into csv file in order to generate graphs to observe different patterns, based on which we are able to analyze and draw our conclusion.
(3)Since so many statistics need to be produced and analyzed, we also wrote bash scripts to automate different experiments, which change parameters and run the tcl file and perl file in a nested loop, to produce large volume of statistics for analysis.
(4)Based on the graphs, we are able to observe the different pattern under different circumstances, establish our hypothesis and verify them according to what we have learned in class or other similar studies.

2. Challenges
(1)Getting familiar with NS2 framework needs time, and we did encounter problems learning how to use it effectively and efficiently. For example, trying to accept command-line arguments from bash takes time to learn.
(2)How to correctly calculate throughput, latency, and drop rate is a big deal. Initially we didn't do it in a feasible way so we didn't get expected results. After we changed our algorithm, we were able to get some interesting results.
(3)Debugging is tedious and it also takes a lot of time. We need to debug differnt code including the tcl files, the perl files as well as the bash scripts.We need to examine the parameters carefully, and coordinate between these different file for the sake of automation. If one file does not work, the bash scripts will not be able to run successfully, which will eventually product emput csv files.

3. Testing our code
Basically we have exp1.tcl, exp2.tcl, and exp3.tcl for the simulations of experiment 1, experiment 2, and experiment 3, respectively. exp1.tcl takes 3 parameters including CBR rate, TCP variants, and trace filename. exp2.tcl takes 3 parameters including CBR rate, TCP variants-pairs, and trace filename and exp3.tcl takes queuing algorithms, TCP variants and trace filename.
we have 3 perl files including throughput, endtoenddelay, and droprate. The throughput file takes the trace file as input file, the csv file as output file, and the node as where to calculate the throughput. The endtoenddelay file takes the trace file as input file, the csv file as output file, and two nodes representing a link as the parameters. The droprate file takes the trace file, the csv file and a single node as well.
The bash scripts for each experiments contains the predefined parameters that we want to specify in the simulation. We have a nested loop to combine those different dimensions.
We test our code based on the pattern of the trace files and the cvs files. If the statistics are not what we were expecting, we want back to the code and find the corresponding parameters. If the topology and simulation are not what we are looking for, it means that there are some problems with the tcl files. If the statistics in csv files are not what we want, it means that the logic in the perl files maybe incorrect. If the produced file names are incorrect or the number is incorrect, it means the bash files are incorrect.
